"""
Shamelessly stolen from:
http://stackoverflow.com/questions/641420/
    how-should-i-log-while-using-multiprocessing-in-python
    
Author: not me.
"""


"""sample code for logging in subprocesses using multiprocessing

* Little handler magic - The main process uses loggers and handlers as normal.
* Only a simple handler is needed in the subprocess that feeds the queue.
* Original logger name from subprocess is preserved when logged in main
  process.
* As in the other implementations, a thread reads the queue and calls the
  handlers. Except in this implementation, the thread is defined outside of a
  handler, which makes the logger definitions simpler.
* Works with multiple handlers.  If the logger in the main process defines
  multiple handlers, they will all be fed records generated by the
  subprocesses loggers.

tested with Python 2.5 and 2.6 on Linux and Windows

"""

import logging
import threading 
import traceback
import sys

import config
import crawlglobs

def setupSubProcessLogger(pname, log_q):
    """Sets up SubProcessLogger to only have the SubProcessHandler. The
    arguments are a custom name for the process and the shared queue between
    main and the subprocesses. Returns the logger created.
    """
    # create the logger to use.
    logger = logging.getLogger(pname)
    # The only handler desired is the SubProcessLogHandler.  If any others
    # exist, remove them. In this case, on Unix and Linux the StreamHandler
    # will be inherited.
    for handler in logger.handlers:
        # just a check for my sanity
        #if not isinstance(handler, SubProcessLogHandler)
        logger.removeHandler(handler)
    # add the handler
    handler = SubProcessLogHandler(log_q)
    handler.setFormatter(logging.Formatter(config.LOG_FORMAT))
    logger.addHandler(handler)
    # On Windows, the level will not be inherited.  Also, we could just
    # set the level to log everything here and filter it in the main
    # process handlers.  For now, just set it from the global default.
    logger.setLevel(crawlglobs.log_level)
    return logger

class SubProcessLogHandler(logging.Handler):
    """Handler used by the subprocesses. It puts items on the shared queue for 
    the main process to log.
    """

    def __init__(self, queue):
        logging.Handler.__init__(self)
        self.queue = queue

    def emit(self, record):
        self.queue.put(record)

class LogQueueReader(threading.Thread):
    """Thread to write subprocesses log records to main process log. This 
    thread reads the records written by subprocesses and writes them to
    the handlers defined in the main process's handlers.
    """

    def __init__(self, queue):
        threading.Thread.__init__(self)
        self.queue = queue
        self.daemon = True

    def run(self):
        """read from the queue and write to the log handlers

        The logging documentation says logging is thread safe, so there
        shouldn't be contention between normal logging (from the main
        process) and this thread.

        Note that we're using the name of the original logger.

        """
        # Thanks Mike for the error checking code.
        while True:
            try:
                record = self.queue.get()
                # get the logger for this record
                logger = logging.getLogger(config.MAIN_LOGGER_NAME)
                logger.callHandlers(record)
            except (KeyboardInterrupt, SystemExit):
                raise
            except EOFError:
                break
            except:
                traceback.print_exc(file=sys.stderr)
